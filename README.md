# 百度网盘AI大赛——图像处理挑战赛：文档图像超分

> 这是一个基于PaddlePaddle的文档图像超分的解决方案，本方案在B榜上取得了第3名的成绩，本文将介绍本方案的一些细节，以及如何使用本方案进行预测。

## 项目描述
文档图像超分是一个较为底层的任务，即将较小尺寸的图像进行放大。
本方案使用了基于CNN网络，通过对输入图像进行不同层的特征提取，
然后，通过上采样头进行图像放大，最终实现文档图像超分的任务。


## 项目结构
```
-|bdpan_sr
-|checkpoint
-|dataset
-|dowdyboy_lib
-|scripts
-train.py
-predict.py
-calc_norm.py
```
- bdpan_sr: 本项目的模型源代码
- checkpoint: 本项目的模型参数
- dataset: 本项目的数据集
- dowdyboy_lib: 自行编写的基于飞桨的深度学习训练器，详见[这里](https://github.com/dowdyboy/dowdyboy_lib)
- scripts: 本项目的历史版本
- train.py: 训练脚本
- predict.py: 预测脚本
- calc_norm.py: 计算数据集正则参数的脚本

## 数据

本项目训练数据和验证数据由以下组成：

- x：低分辨率图像
- x2：放大两倍的GT图像
- x4：放大四倍的GT图像

本项目测试数据由百度网盘AI大赛提供，
详见[官网](https://aistudio.baidu.com/aistudio/competition/detail/493/0/datasets) 。

训练验证数据下载：

链接：https://pan.baidu.com/s/1c7i4YbnzyVn0yvLzWo9Fvw?pwd=be12
提取码：be12

## 训练
> 将数据集放在dataset文件夹下；
```
|dataset
-|train
-|val
```
> 运行train脚本
```
python ./train.py 
        --train-data-dir
        ./dataset/train/
        --val-data-dir
        ./dataset/val/
        --img-size
        512
        --use-scheduler
        --use-warmup
        --epoch 
        1600
        --batch-size
        1
        --out-dir
        ./output
        --sync-bn
        --lr
        0.0001
```

> 竞赛时，我们使用了1卡NVIDIA A100进行了训练；训练时间较长；

## 预测
> 运行predict.py脚本、最优模型已经保存在checkpoint文件夹下
```
python predict.py 
     <要预测的图像文件夹路径> 
     <pred_x2_dir>
     <pred_x4_dir>
```

## 项目详情

### 数据处理

本方案对原始数据做如下处理：

1.由于原始图像尺寸大，在显存有限情况下，只能对图像进行裁剪。
本次采用的裁切大小为512*512，裁切方式为随机裁切。

2.原始数据量只有3000张左右的图像，数量相对来说较小，
因此必须采用一定的数据增强方案来拓展数据集，
来防止过拟合现象产生。本次采用的数据增强方案有：
水平翻转、垂直翻转、长宽翻转。
数据增强的参考论文有：http://arxiv.org/abs/1710.09412

3.由于本次数据集基本只包含文档图像数据，其与自然图像数据的分布
差异较大，因此可以在输入模型之前进行正规化处理。对于正规化
参数，一般采用image net数据集的均值和方差，但是由于本次数据
集均是文档图像数据，因此需要自行计算均值和方差。

4.本次竞赛并没有提供官方的验证集，本方案自行划分了验证集，
划分方法为：对3000张训练图像进行排序，取最后一百张图像作为
验证集，其余2900张图像作为训练集。

### 网络设计

目前，单图超分辨领域的常用模型有RealSR, ESRGAN, LESRCNN,PAN,SwinIR等，其中大部分模型都是基于CNN架构，同时也存在基于Transformer架构的模型。本次竞赛我们两种方案的baseline都进行了尝试，发现对于文档图像数据，采用CNN架构的模型能够取得更好的性能。我们简单的分析了一下原因，认为由于文档图像数据在结构上较为简单，采用Transformer的自注意力机制和大量的MLP变换，可能会使得模型学习到捷径，从而影响最终模型性能。

因此我们最终确定的方案采用基于CNN的架构，并结合了目前基于CNN架构的不同超分辨模型的特点进行了定制化设计。具体如下：

1.采用了密集的残差连接

超分辨模型的任务市需要对原始图像进行放大操作，由于需要对原有图像的每一个像素放大到4倍或者16倍数，这就对网络模型提出了挑战。超分任务属于低层次任务，而随着卷积层数的加深，
模型往往提取的更多的图像语义信息，而淡化低层次的像素信息。为了应对这个问题，我们的模型增加了大量的残差连接，参考了densenet的结构和Residual-in-Residual
Dense Block的结构进行了设计。

2.采用了差异化学习的上采用头

生成式的任务，相对于如分类等的其他任务，对模型的学习能力提出了更
高的要求。可以想到的是，如果让模型能够仅仅学习差异，而不是从头进
行全量的学习，应该可以一定程度的降低学习难度。综上，我们的模型
设计上，采用了多尺度的差异化头，一方面从模型提取的特征图上进
行学习，另一方面，直接从原始的输入图像上进行学习，两者融合，产
生最终的输出图像。

3.同时进行多尺度的超分图像学习

本次赛题要求对原始图像进行两倍放大和四倍放大，最简单的方法是训练
两个模型，分别进行两个尺度的放大。然而，这样做会使得模型的预测
效率大大降低。对于这个问题，我们在上采用头的结构上进行了优化，
使得其进行了两次上采样，从而可以同时学习两倍放大和四倍放大。

4.采用像素注意力机制和通道注意力机制

经过对数据的分析，文档图像具有较为明显的特点，即黑白分明。因此，
我们考虑使用像素注意力机制和通道注意力机制，对backbone进行修
改，使得backbone能够更加充分的提取图像的特征，从而提升上采样
头的还原精度。

### 训练方案

我们使用Adam优化器，并使用CosineAnnealingRestartLR调整学习率，初始学习率设置为1e-4。

我们在全量数据集上进行1600个epoch的训练，并在每个epoch的学习结束后，在验证集上进行验证，计算psnr和ssim，最终输出模型为在验证集上表现最佳的模型。
我们的整个实验过程在一张NVIDIA A100 GPU上进行。

### 技术架构

我们采用paddle作为基础框架。另外，我们在paddle的基础上，
封装了一个深度学习训练器（trainer），使得能够更加方便的进行模型
存储、半精度训练、多卡训练、日志打印等。这个项目的
地址为：https://github.com/dowdyboy/dowdyboy_lib 。
